{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b10adc8b4b24ff954d99c62f6bf1e45e0f3a936f77a846b176af4c6827cb0e64"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.config import list_physical_devices\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY, testX, testY = utils.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_vgglike():\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "\n",
    "    x = layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same')(inputs)\n",
    "    x = layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = layers.MaxPool2D((2,2))(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = layers.MaxPool2D((2,2))(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = layers.MaxPool2D((2,2))(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    outputs = layers.Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"custom_vgglike\")\n",
    "    opt = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy', keras.metrics.AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = keras.callbacks.ModelCheckpoint('models/vgglike', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "- 2s 16ms/step - loss: 0.8250 - categorical_accuracy: 0.7067 - auc: 0.9610 - val_loss: 0.7844 - val_categorical_accuracy: 0.7242 - val_auc: 0.9646\n",
      "Epoch 110/200\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.8179 - categorical_accuracy: 0.7079 - auc: 0.9617 - val_loss: 0.7720 - val_categorical_accuracy: 0.7302 - val_auc: 0.9657\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 111/200\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.8182 - categorical_accuracy: 0.7117 - auc: 0.9618 - val_loss: 0.7697 - val_categorical_accuracy: 0.7291 - val_auc: 0.9659\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 112/200\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.8150 - categorical_accuracy: 0.7117 - auc: 0.9618 - val_loss: 0.7796 - val_categorical_accuracy: 0.7260 - val_auc: 0.9652\n",
      "Epoch 113/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.8077 - categorical_accuracy: 0.7141 - auc: 0.9625 - val_loss: 0.7562 - val_categorical_accuracy: 0.7365 - val_auc: 0.9674\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 114/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.8028 - categorical_accuracy: 0.7147 - auc: 0.9629 - val_loss: 0.7606 - val_categorical_accuracy: 0.7361 - val_auc: 0.9670\n",
      "Epoch 115/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.7949 - categorical_accuracy: 0.7189 - auc: 0.9637 - val_loss: 0.7553 - val_categorical_accuracy: 0.7384 - val_auc: 0.9673\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 116/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.8069 - categorical_accuracy: 0.7145 - auc: 0.9625 - val_loss: 0.7571 - val_categorical_accuracy: 0.7372 - val_auc: 0.9673\n",
      "Epoch 117/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7972 - categorical_accuracy: 0.7171 - auc: 0.9636 - val_loss: 0.7573 - val_categorical_accuracy: 0.7348 - val_auc: 0.9671\n",
      "Epoch 118/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.7943 - categorical_accuracy: 0.7169 - auc: 0.9638 - val_loss: 0.7589 - val_categorical_accuracy: 0.7326 - val_auc: 0.9668\n",
      "Epoch 119/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.7845 - categorical_accuracy: 0.7217 - auc: 0.9646 - val_loss: 0.7504 - val_categorical_accuracy: 0.7397 - val_auc: 0.9674\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 120/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.7904 - categorical_accuracy: 0.7174 - auc: 0.9640 - val_loss: 0.7747 - val_categorical_accuracy: 0.7292 - val_auc: 0.9651\n",
      "Epoch 121/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7883 - categorical_accuracy: 0.7198 - auc: 0.9640 - val_loss: 0.7508 - val_categorical_accuracy: 0.7422 - val_auc: 0.9677\n",
      "Epoch 122/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7869 - categorical_accuracy: 0.7222 - auc: 0.9642 - val_loss: 0.7599 - val_categorical_accuracy: 0.7349 - val_auc: 0.9664\n",
      "Epoch 123/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.7790 - categorical_accuracy: 0.7246 - auc: 0.9650 - val_loss: 0.7431 - val_categorical_accuracy: 0.7411 - val_auc: 0.9681\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 124/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.7802 - categorical_accuracy: 0.7232 - auc: 0.9650 - val_loss: 0.7425 - val_categorical_accuracy: 0.7430 - val_auc: 0.9682\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 125/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.7733 - categorical_accuracy: 0.7267 - auc: 0.9654 - val_loss: 0.7370 - val_categorical_accuracy: 0.7437 - val_auc: 0.9686\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 126/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7779 - categorical_accuracy: 0.7287 - auc: 0.9649 - val_loss: 0.7379 - val_categorical_accuracy: 0.7440 - val_auc: 0.9684\n",
      "Epoch 127/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7656 - categorical_accuracy: 0.7302 - auc: 0.9662 - val_loss: 0.7255 - val_categorical_accuracy: 0.7473 - val_auc: 0.9692\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 128/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7606 - categorical_accuracy: 0.7338 - auc: 0.9665 - val_loss: 0.7222 - val_categorical_accuracy: 0.7507 - val_auc: 0.9699\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 129/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7643 - categorical_accuracy: 0.7317 - auc: 0.9662 - val_loss: 0.7304 - val_categorical_accuracy: 0.7472 - val_auc: 0.9693\n",
      "Epoch 130/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7526 - categorical_accuracy: 0.7333 - auc: 0.9673 - val_loss: 0.7245 - val_categorical_accuracy: 0.7488 - val_auc: 0.9694\n",
      "Epoch 131/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7583 - categorical_accuracy: 0.7296 - auc: 0.9670 - val_loss: 0.7344 - val_categorical_accuracy: 0.7439 - val_auc: 0.9684\n",
      "Epoch 132/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7557 - categorical_accuracy: 0.7323 - auc: 0.9668 - val_loss: 0.7197 - val_categorical_accuracy: 0.7514 - val_auc: 0.9696\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 133/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7560 - categorical_accuracy: 0.7326 - auc: 0.9669 - val_loss: 0.7340 - val_categorical_accuracy: 0.7436 - val_auc: 0.9684\n",
      "Epoch 134/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7559 - categorical_accuracy: 0.7329 - auc: 0.9670 - val_loss: 0.7307 - val_categorical_accuracy: 0.7448 - val_auc: 0.9686\n",
      "Epoch 135/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7398 - categorical_accuracy: 0.7378 - auc: 0.9683 - val_loss: 0.7208 - val_categorical_accuracy: 0.7461 - val_auc: 0.9697\n",
      "Epoch 136/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7437 - categorical_accuracy: 0.7366 - auc: 0.9680 - val_loss: 0.7034 - val_categorical_accuracy: 0.7573 - val_auc: 0.9712\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 137/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.7394 - categorical_accuracy: 0.7385 - auc: 0.9683 - val_loss: 0.7233 - val_categorical_accuracy: 0.7507 - val_auc: 0.9692\n",
      "Epoch 138/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7538 - categorical_accuracy: 0.7340 - auc: 0.9671 - val_loss: 0.7017 - val_categorical_accuracy: 0.7580 - val_auc: 0.9713\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 139/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.7364 - categorical_accuracy: 0.7348 - auc: 0.9688 - val_loss: 0.7176 - val_categorical_accuracy: 0.7536 - val_auc: 0.9696\n",
      "Epoch 140/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7432 - categorical_accuracy: 0.7370 - auc: 0.9681 - val_loss: 0.7037 - val_categorical_accuracy: 0.7555 - val_auc: 0.9710\n",
      "Epoch 141/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7277 - categorical_accuracy: 0.7425 - auc: 0.9692 - val_loss: 0.7237 - val_categorical_accuracy: 0.7510 - val_auc: 0.9694\n",
      "Epoch 142/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7251 - categorical_accuracy: 0.7441 - auc: 0.9696 - val_loss: 0.7039 - val_categorical_accuracy: 0.7548 - val_auc: 0.9707\n",
      "Epoch 143/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7265 - categorical_accuracy: 0.7442 - auc: 0.9691 - val_loss: 0.6955 - val_categorical_accuracy: 0.7582 - val_auc: 0.9717\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 144/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7235 - categorical_accuracy: 0.7462 - auc: 0.9696 - val_loss: 0.6971 - val_categorical_accuracy: 0.7611 - val_auc: 0.9716\n",
      "Epoch 145/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7168 - categorical_accuracy: 0.7450 - auc: 0.9702 - val_loss: 0.7155 - val_categorical_accuracy: 0.7522 - val_auc: 0.9697\n",
      "Epoch 146/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7225 - categorical_accuracy: 0.7446 - auc: 0.9698 - val_loss: 0.7180 - val_categorical_accuracy: 0.7522 - val_auc: 0.9696\n",
      "Epoch 147/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7224 - categorical_accuracy: 0.7458 - auc: 0.9698 - val_loss: 0.7066 - val_categorical_accuracy: 0.7552 - val_auc: 0.9705\n",
      "Epoch 148/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7101 - categorical_accuracy: 0.7515 - auc: 0.9705 - val_loss: 0.7042 - val_categorical_accuracy: 0.7548 - val_auc: 0.9706\n",
      "Epoch 149/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7186 - categorical_accuracy: 0.7477 - auc: 0.9700 - val_loss: 0.6957 - val_categorical_accuracy: 0.7595 - val_auc: 0.9715\n",
      "Epoch 150/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7102 - categorical_accuracy: 0.7482 - auc: 0.9706 - val_loss: 0.6901 - val_categorical_accuracy: 0.7579 - val_auc: 0.9716\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 151/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.7147 - categorical_accuracy: 0.7463 - auc: 0.9703 - val_loss: 0.6794 - val_categorical_accuracy: 0.7633 - val_auc: 0.9727\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 152/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.7012 - categorical_accuracy: 0.7513 - auc: 0.9714 - val_loss: 0.6883 - val_categorical_accuracy: 0.7653 - val_auc: 0.9721\n",
      "Epoch 153/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.7039 - categorical_accuracy: 0.7506 - auc: 0.9711 - val_loss: 0.6785 - val_categorical_accuracy: 0.7659 - val_auc: 0.9728\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 154/200\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.7053 - categorical_accuracy: 0.7503 - auc: 0.9711 - val_loss: 0.6806 - val_categorical_accuracy: 0.7629 - val_auc: 0.9725\n",
      "Epoch 155/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7048 - categorical_accuracy: 0.7507 - auc: 0.9710 - val_loss: 0.6855 - val_categorical_accuracy: 0.7636 - val_auc: 0.9720\n",
      "Epoch 156/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.7086 - categorical_accuracy: 0.7475 - auc: 0.9709 - val_loss: 0.6803 - val_categorical_accuracy: 0.7643 - val_auc: 0.9724\n",
      "Epoch 157/200\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.6975 - categorical_accuracy: 0.7557 - auc: 0.9717 - val_loss: 0.6736 - val_categorical_accuracy: 0.7666 - val_auc: 0.9732\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 158/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6947 - categorical_accuracy: 0.7537 - auc: 0.9720 - val_loss: 0.6766 - val_categorical_accuracy: 0.7673 - val_auc: 0.9728\n",
      "Epoch 159/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6961 - categorical_accuracy: 0.7534 - auc: 0.9716 - val_loss: 0.6641 - val_categorical_accuracy: 0.7723 - val_auc: 0.9737\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 160/200\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.6870 - categorical_accuracy: 0.7574 - auc: 0.9724 - val_loss: 0.6801 - val_categorical_accuracy: 0.7645 - val_auc: 0.9726\n",
      "Epoch 161/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6785 - categorical_accuracy: 0.7602 - auc: 0.9732 - val_loss: 0.6687 - val_categorical_accuracy: 0.7697 - val_auc: 0.9733\n",
      "Epoch 162/200\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.6850 - categorical_accuracy: 0.7546 - auc: 0.9727 - val_loss: 0.6778 - val_categorical_accuracy: 0.7682 - val_auc: 0.9726\n",
      "Epoch 163/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.6834 - categorical_accuracy: 0.7562 - auc: 0.9727 - val_loss: 0.6628 - val_categorical_accuracy: 0.7731 - val_auc: 0.9738\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 164/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.6810 - categorical_accuracy: 0.7624 - auc: 0.9729 - val_loss: 0.6605 - val_categorical_accuracy: 0.7718 - val_auc: 0.9741\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 165/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.6798 - categorical_accuracy: 0.7606 - auc: 0.9727 - val_loss: 0.6884 - val_categorical_accuracy: 0.7607 - val_auc: 0.9717\n",
      "Epoch 166/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.6735 - categorical_accuracy: 0.7625 - auc: 0.9735 - val_loss: 0.6810 - val_categorical_accuracy: 0.7642 - val_auc: 0.9723\n",
      "Epoch 167/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.6806 - categorical_accuracy: 0.7613 - auc: 0.9730 - val_loss: 0.6797 - val_categorical_accuracy: 0.7646 - val_auc: 0.9725\n",
      "Epoch 168/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6690 - categorical_accuracy: 0.7604 - auc: 0.9740 - val_loss: 0.6532 - val_categorical_accuracy: 0.7743 - val_auc: 0.9746\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 169/200\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.6676 - categorical_accuracy: 0.7663 - auc: 0.9740 - val_loss: 0.6606 - val_categorical_accuracy: 0.7693 - val_auc: 0.9739\n",
      "Epoch 170/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6665 - categorical_accuracy: 0.7666 - auc: 0.9739 - val_loss: 0.6594 - val_categorical_accuracy: 0.7725 - val_auc: 0.9740\n",
      "Epoch 171/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6640 - categorical_accuracy: 0.7646 - auc: 0.9744 - val_loss: 0.6544 - val_categorical_accuracy: 0.7749 - val_auc: 0.9745\n",
      "Epoch 172/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6658 - categorical_accuracy: 0.7646 - auc: 0.9739 - val_loss: 0.6609 - val_categorical_accuracy: 0.7746 - val_auc: 0.9737\n",
      "Epoch 173/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6571 - categorical_accuracy: 0.7675 - auc: 0.9746 - val_loss: 0.6588 - val_categorical_accuracy: 0.7719 - val_auc: 0.9741\n",
      "Epoch 174/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6554 - categorical_accuracy: 0.7684 - auc: 0.9748 - val_loss: 0.6526 - val_categorical_accuracy: 0.7751 - val_auc: 0.9744\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 175/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6565 - categorical_accuracy: 0.7662 - auc: 0.9746 - val_loss: 0.6492 - val_categorical_accuracy: 0.7779 - val_auc: 0.9745\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 176/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6611 - categorical_accuracy: 0.7681 - auc: 0.9743 - val_loss: 0.6590 - val_categorical_accuracy: 0.7730 - val_auc: 0.9738\n",
      "Epoch 177/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6576 - categorical_accuracy: 0.7679 - auc: 0.9746 - val_loss: 0.6505 - val_categorical_accuracy: 0.7764 - val_auc: 0.9744\n",
      "Epoch 178/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6476 - categorical_accuracy: 0.7706 - auc: 0.9753 - val_loss: 0.6425 - val_categorical_accuracy: 0.7777 - val_auc: 0.9753\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 179/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6481 - categorical_accuracy: 0.7713 - auc: 0.9752 - val_loss: 0.6519 - val_categorical_accuracy: 0.7758 - val_auc: 0.9744\n",
      "Epoch 180/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6468 - categorical_accuracy: 0.7728 - auc: 0.9755 - val_loss: 0.6369 - val_categorical_accuracy: 0.7784 - val_auc: 0.9757\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 181/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6465 - categorical_accuracy: 0.7709 - auc: 0.9756 - val_loss: 0.6490 - val_categorical_accuracy: 0.7770 - val_auc: 0.9745\n",
      "Epoch 182/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6468 - categorical_accuracy: 0.7706 - auc: 0.9755 - val_loss: 0.6377 - val_categorical_accuracy: 0.7805 - val_auc: 0.9757\n",
      "Epoch 183/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6441 - categorical_accuracy: 0.7699 - auc: 0.9758 - val_loss: 0.6516 - val_categorical_accuracy: 0.7747 - val_auc: 0.9745\n",
      "Epoch 184/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6449 - categorical_accuracy: 0.7725 - auc: 0.9758 - val_loss: 0.6467 - val_categorical_accuracy: 0.7759 - val_auc: 0.9748\n",
      "Epoch 185/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6384 - categorical_accuracy: 0.7743 - auc: 0.9762 - val_loss: 0.6315 - val_categorical_accuracy: 0.7810 - val_auc: 0.9758\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 186/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6337 - categorical_accuracy: 0.7750 - auc: 0.9763 - val_loss: 0.6416 - val_categorical_accuracy: 0.7800 - val_auc: 0.9753\n",
      "Epoch 187/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6360 - categorical_accuracy: 0.7741 - auc: 0.9761 - val_loss: 0.6341 - val_categorical_accuracy: 0.7836 - val_auc: 0.9757\n",
      "Epoch 188/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6402 - categorical_accuracy: 0.7713 - auc: 0.9761 - val_loss: 0.6419 - val_categorical_accuracy: 0.7783 - val_auc: 0.9751\n",
      "Epoch 189/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6308 - categorical_accuracy: 0.7785 - auc: 0.9765 - val_loss: 0.6347 - val_categorical_accuracy: 0.7826 - val_auc: 0.9758\n",
      "Epoch 190/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6368 - categorical_accuracy: 0.7774 - auc: 0.9761 - val_loss: 0.6415 - val_categorical_accuracy: 0.7803 - val_auc: 0.9752\n",
      "Epoch 191/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6372 - categorical_accuracy: 0.7760 - auc: 0.9761 - val_loss: 0.6384 - val_categorical_accuracy: 0.7818 - val_auc: 0.9754\n",
      "Epoch 192/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6279 - categorical_accuracy: 0.7799 - auc: 0.9765 - val_loss: 0.6304 - val_categorical_accuracy: 0.7825 - val_auc: 0.9759\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 193/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6205 - categorical_accuracy: 0.7793 - auc: 0.9774 - val_loss: 0.6310 - val_categorical_accuracy: 0.7805 - val_auc: 0.9758\n",
      "Epoch 194/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6209 - categorical_accuracy: 0.7810 - auc: 0.9772 - val_loss: 0.6394 - val_categorical_accuracy: 0.7808 - val_auc: 0.9753\n",
      "Epoch 195/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6192 - categorical_accuracy: 0.7816 - auc: 0.9775 - val_loss: 0.6191 - val_categorical_accuracy: 0.7853 - val_auc: 0.9770\n",
      "INFO:tensorflow:Assets written to: models/vgglike/assets\n",
      "Epoch 196/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6267 - categorical_accuracy: 0.7793 - auc: 0.9769 - val_loss: 0.6278 - val_categorical_accuracy: 0.7839 - val_auc: 0.9758\n",
      "Epoch 197/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6343 - categorical_accuracy: 0.7752 - auc: 0.9762 - val_loss: 0.6343 - val_categorical_accuracy: 0.7816 - val_auc: 0.9752\n",
      "Epoch 198/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6210 - categorical_accuracy: 0.7792 - auc: 0.9774 - val_loss: 0.6266 - val_categorical_accuracy: 0.7856 - val_auc: 0.9764\n",
      "Epoch 199/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6102 - categorical_accuracy: 0.7825 - auc: 0.9781 - val_loss: 0.6251 - val_categorical_accuracy: 0.7846 - val_auc: 0.9763\n",
      "Epoch 200/200\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.6161 - categorical_accuracy: 0.7866 - auc: 0.9776 - val_loss: 0.6328 - val_categorical_accuracy: 0.7834 - val_auc: 0.9756\n"
     ]
    }
   ],
   "source": [
    "model = custom_vgglike()\n",
    "history = model.fit(x=trainX, y=trainY, batch_size=512, epochs=200, callbacks=callback, validation_data=(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model('models/vgglike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 30s 50ms/step - loss: 0.6190 - categorical_accuracy: 0.7853 - auc: 0.9770\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.6190477609634399, 0.7853000164031982, 0.9769587516784668]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "best_model.evaluate(x=testX, y=testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#architecture: https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/"
   ]
  }
 ]
}